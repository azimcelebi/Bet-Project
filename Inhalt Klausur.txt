Spickblatt:
- V2 Folie 19
- V3 Folie 7 (Nominal-, Ordinal-, Interval- und Raioskala), Folie 20-23
- V4 Folie 12, 21, 27
- V5 Folie 3, 4, 5, 10, 26
- V6 Folie 3, 4, 9, 15
- V7 Folie 4, 16, 18
- V8 Folie 5, 6, 7, 8, 11, 14, 15, 18, 21, 22
- V9 Folie 4, 5, 9, 14, 23
- V10 Folie 10-12, 13-15, 16, 22/26
- V11 Folie 19
- V12 Folie 19, 20, 21-22
- Python Beispiel

Info:
- Ein Hyperparameter ist eine Einstellung, die du vor dem Training eines Machine-Learning-Modells festlegst und die beeinflusst, wie das Modell lernt.


Vorlesungsfolien 2:
- Merkmale und Label (Zielgröße), Arten von Label
- Regression Basics
- Klassifikation Basics
- Clustering Basics
- Arten von ML Verfahren (Supervised-, Unsupervised-, Reinforcement- und Self-Supervised Learning)
- Offline- und Offline Learning
- Instanzbasiertes- und Modellbasiertes Lernen
- Mögliche Probleme bei ML Algorithmen
- Nicht repräsentative Trainingsdaten - Stichprobenverzerrung
- Underfitting und Overfitting

Vorlesungsfolien 3:
- Warum Statistik für Machine Learning?
- Datensätze
- Tabellarische Daten (Nominal-, Ordinal- Interval- und Ratioskala)
- Skalenniveaus im Machine Learning
- Wahrscheinlichkeitsverteilungen
- Binomial, Poisson, Normal, Exponential
- Beispiele für Wahrscheinlichkeitsverteilungen
- Statistische Kennzahlen (Lagermaße, Streuungsmaße und Visualisierungen)
- Erwartungswert (arithmetisches Mittel)
- Standardabweichung (Streuung der Werte)
- Korrelation Kovarianz

Vorlesungsfolien 4:
- Pandas
- DataFrame anlegen und erweitern
- Probleme in Datensätzen
- Umgang mit fehlenden Daten
- Grundlegende Matrix-Operationen (Matrixmultiplikation, Matrix-Vektor Mulitplikation, Matrix Transpnonieren)
- Garbage In Garbage Out - Warum gute Features entscheidend sind
- Datenvorverarbeitung und Feature Engineering
- Skalieren von Merkmalen
- Normalisierung
- Feature Engineering und Selection
- Datensätze Analysieren - Kovarianz und Korrelationskoeffizient

Vorlesungsfolien 5:
- Linerare Regression (Einfache und Lineare Regression)
- Bewertung einer Modellfunktion (Summe der absoluten Fehler, Summe der Fehlerquadrate)
- Linerare Regression Modellfunktion und Mean Absolute Error, Mean Squared Error, Root Mean Squared Error
- Linearität
- Homoskedastizität
- Unabhängigkeit der Fehler
- Normalverteilung der Fehler
- Minimierung der Kostenfunktion: Normalgleichung
- Berechnung der Normalgleichung
- Direkte Lösungen vs iterative Optimierung
- Polynomielle Regression
- Regularisierung


Vorlesungsfolien 6:
- Gradientenverfahren
- Lernrate bestimmen
- Lernkurven
- Stochastisches Gradientenverfahren
- Mini-Batch Gradientenverfahren 

Vorlesungsfolien 7:
- Accuracy als Kostenfunktion
- Logistische Regression
- Binäre Logistische Regression
- Multinomiale logistische Regression
- Klassifikationsprobleme
- Maximum Likelihood Prinzip
- Kostenfunktion für die Logistische Regression
- Klassifikation und Fehler

Vorlesungsfolien 8:
- Accuracy
- Recall
- Precision
- F1-Score
- Specificity
- Precision vs Recall
- Classification Accuracy
- Konfusionsmatrix
- Accuracy
- ROC Kurve 
- Elastic Net
- Early Stopping
- Kreuzvalidierung

Vorlesungsfolien 9:
- Naive Bayes & KNN
- K-Nearest Neighbors

Vorlesungsfolien 10:
- Entscheidungsbäume
- Gini Impurity (Gini Unreinheit)
- Information Gain
- CART
- Ensemble Methoden - Bagging und Boosting

Vorlesungsfolien 11:
- Hard-Margin Classifier
- Soft-Margin Classifier
- Support Vector Classifier
- Support Vector Machines

Vorlesungsfolien 12:
- Künstliches Neuron
- Einfache Lineare Neuronale Netze
- Perzeptron Modell- und Kostenfunktion
- Perzeptron Lernregel
- Neuronales Netzwerk - Notationen und Berechnungen


